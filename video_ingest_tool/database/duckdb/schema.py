import duckdb
import structlog
from .connection import get_db_connection # Import from sibling module

logger = structlog.get_logger(__name__)

APP_DATA_SCHEMA = "app_data"
PREFECT_SCHEMA = "prefect_orchestration" # Reserved for Prefect

def create_schemas(con: "duckdb.DuckDBPyConnection"):
    """Creates the necessary schemas if they don't exist."""
    try:
        con.execute(f"CREATE SCHEMA IF NOT EXISTS {APP_DATA_SCHEMA};")
        logger.info(f"Ensured schema '{APP_DATA_SCHEMA}' exists.")
        con.execute(f"CREATE SCHEMA IF NOT EXISTS {PREFECT_SCHEMA};")
        logger.info(f"Ensured schema '{PREFECT_SCHEMA}' exists for future Prefect use.")
    except Exception as e:
        logger.error("Failed to create schemas", error=str(e))
        raise

def create_clips_table(con: "duckdb.DuckDBPyConnection"):
    """Creates the 'clips' table in the app_data schema."""
    table_name = f"{APP_DATA_SCHEMA}.clips"
    try:
        # Note: UUIDs are generated by the application before insertion
        con.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id UUID PRIMARY KEY,
                file_path VARCHAR NOT NULL,
                local_path VARCHAR NOT NULL,
                file_name VARCHAR NOT NULL,
                file_checksum VARCHAR UNIQUE NOT NULL,
                file_size_bytes BIGINT NOT NULL,
                duration_seconds DOUBLE,
                created_at TIMESTAMP,
                processed_at TIMESTAMP,
                updated_at TIMESTAMP,

                width INTEGER,
                height INTEGER,
                frame_rate DOUBLE,
                codec VARCHAR,
                container VARCHAR,
                
                camera_make VARCHAR,
                camera_model VARCHAR,
                camera_details JSON, 
                
                content_category VARCHAR,
                content_summary VARCHAR,
                content_tags VARCHAR[],      -- List of strings
                searchable_content VARCHAR,  -- For FTS, populated by app
                
                full_transcript TEXT,        -- Full transcript text from analysis/transcripts table
                transcript_preview VARCHAR,  -- Short preview
                
                thumbnails VARCHAR[],        -- List of generated thumbnail file paths/names
                thumbnail_url VARCHAR,       -- Path/URL to the primary selected thumbnail
                all_thumbnail_urls JSON,     -- JSON array of objects for all thumbnails (path, rank, etc.)
                ai_selected_thumbnails_metadata JSON, -- Metadata for AI selected thumbnails (rank, desc, reason)

                technical_metadata JSON,
                audio_tracks JSON,           -- Array of audio track objects
                subtitle_tracks JSON,        -- Array of subtitle track objects
                
                -- Vector Embeddings (merged from 'vectors' table)
                summary_embedding FLOAT[1024],    -- BAAI/bge-m3
                keyword_embedding FLOAT[1024],    -- BAAI/bge-m3
                thumbnail_1_embedding FLOAT[768], -- Specific thumbnail embedding
                thumbnail_2_embedding FLOAT[768],
                thumbnail_3_embedding FLOAT[768]
            );
        """)
        logger.info(f"Table '{table_name}' created or already exists.")
    except Exception as e:
        logger.error(f"Failed to create table '{table_name}'", error=str(e))
        raise

def create_segments_table(con: "duckdb.DuckDBPyConnection"):
    """Creates the 'segments' table in the app_data schema."""
    table_name = f"{APP_DATA_SCHEMA}.segments"
    try:
        con.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id UUID PRIMARY KEY,
                clip_id UUID NOT NULL REFERENCES {APP_DATA_SCHEMA}.clips(id),
                segment_index INTEGER NOT NULL,
                start_time_seconds DOUBLE NOT NULL,
                end_time_seconds DOUBLE NOT NULL,
                duration_seconds DOUBLE,
                segment_type VARCHAR DEFAULT 'auto',
                speaker_id VARCHAR,
                segment_description VARCHAR,
                segment_content TEXT,        -- Transcript part for this segment
                keyframe_timestamp DOUBLE,
                segment_embedding FLOAT[1024], -- If segments also get embeddings
                created_at TIMESTAMP DEFAULT current_timestamp,
                UNIQUE(clip_id, segment_index)
            );
        """)
        logger.info(f"Table '{table_name}' created or already exists.")
    except Exception as e:
        logger.error(f"Failed to create table '{table_name}'", error=str(e))
        raise

def create_analysis_table(con: "duckdb.DuckDBPyConnection"):
    """Creates the 'analysis' table in the app_data schema."""
    table_name = f"{APP_DATA_SCHEMA}.analysis"
    try:
        con.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                id UUID PRIMARY KEY,
                clip_id UUID NOT NULL REFERENCES {APP_DATA_SCHEMA}.clips(id),
                -- segment_id UUID NULL REFERENCES {APP_DATA_SCHEMA}.segments(id) ON DELETE CASCADE, -- If analysis can be segment-specific
                analysis_type VARCHAR NOT NULL, -- e.g., 'ai_summary', 'technical'
                analysis_scope VARCHAR NOT NULL, -- e.g., 'full_clip', 'segment'
                ai_model VARCHAR,
                content_category VARCHAR,
                usability_rating VARCHAR,
                speaker_count INTEGER,
                visual_analysis JSON,
                audio_analysis JSON,
                content_analysis JSON,
                analysis_summary JSON,    -- General summary object
                ai_analysis JSON,         -- Full dump of AI analysis output
                analysis_file_path VARCHAR, -- Path to any generated analysis file (e.g., JSON report)
                created_at TIMESTAMP DEFAULT current_timestamp
            );
        """)
        logger.info(f"Table '{table_name}' created or already exists.")
    except Exception as e:
        logger.error(f"Failed to create table '{table_name}'", error=str(e))
        raise

def create_transcripts_table(con: "duckdb.DuckDBPyConnection"):
    """Creates the 'transcripts' table in the app_data schema."""
    table_name = f"{APP_DATA_SCHEMA}.transcripts"
    try:
        con.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_name} (
                clip_id UUID PRIMARY KEY REFERENCES {APP_DATA_SCHEMA}.clips(id),
                full_text TEXT NOT NULL,
                segments JSON NOT NULL,        -- JSON array of transcript segments with timecodes
                speakers JSON,               -- JSON array of speaker diarization info
                non_speech_events JSON,      -- JSON array of detected non-speech events
                transcript_embedding FLOAT[1024], -- If full transcripts get embeddings
                created_at TIMESTAMP DEFAULT current_timestamp
            );
        """)
        logger.info(f"Table '{table_name}' created or already exists.")
    except Exception as e:
        logger.error(f"Failed to create table '{table_name}'", error=str(e))
        raise

# def add_foreign_keys(con: "duckdb.DuckDBPyConnection"): # Removed as FKs are now inline
#     """Adds foreign keys after all tables are created."""
#     logger.info("Attempting to add foreign keys...")
#     fk_commands = [
#         f"ALTER TABLE {APP_DATA_SCHEMA}.segments ADD CONSTRAINT fk_segments_clip_id FOREIGN KEY (clip_id) REFERENCES {APP_DATA_SCHEMA}.clips(id) ON DELETE CASCADE;",
#         f"ALTER TABLE {APP_DATA_SCHEMA}.analysis ADD CONSTRAINT fk_analysis_clip_id FOREIGN KEY (clip_id) REFERENCES {APP_DATA_SCHEMA}.clips(id) ON DELETE CASCADE;",
#         # f"ALTER TABLE {APP_DATA_SCHEMA}.analysis ADD CONSTRAINT fk_analysis_segment_id FOREIGN KEY (segment_id) REFERENCES {APP_DATA_SCHEMA}.segments(id) ON DELETE CASCADE;", # If segment_id is used
#         f"ALTER TABLE {APP_DATA_SCHEMA}.transcripts ADD CONSTRAINT fk_transcripts_clip_id FOREIGN KEY (clip_id) REFERENCES {APP_DATA_SCHEMA}.clips(id) ON DELETE CASCADE;"
#     ]
#     for command in fk_commands:
#         try:
#             con.execute(command)
#             logger.info(f"Executed: {command.split('ADD CONSTRAINT')[1].split('FOREIGN KEY')[0].strip()}")
#         except duckdb.CatalogException as e:
#             if "already exists" in str(e).lower() or "constraint with name" in str(e).lower() : # Check if FK already exists
#                 logger.debug(f"Foreign key in command '{command.split('ADD CONSTRAINT')[1].split('FOREIGN KEY')[0].strip()}' likely already exists: {e}")
#             else:
#                 logger.error(f"Failed to add foreign key: {command}", error=str(e))
#                 # raise # Optionally re-raise if FKs are critical for initial setup
#         except Exception as e:
#             logger.error(f"Failed to add foreign key: {command}", error=str(e))
#             # raise

def create_indexes(con: "duckdb.DuckDBPyConnection"):
    """Creates FTS, HNSW, and other necessary indexes."""
    logger.info("Attempting to create indexes...")
    try:
        # FTS Indexes
        con.execute(f"PRAGMA create_fts_index('{APP_DATA_SCHEMA}.clips', 'id', 'file_name', 'content_summary', 'transcript_preview', 'searchable_content', 'content_tags', overwrite=1);")
        logger.info(f"FTS index created for {APP_DATA_SCHEMA}.clips.")
        
        con.execute(f"PRAGMA create_fts_index('{APP_DATA_SCHEMA}.segments', 'id', 'segment_description', 'segment_content', overwrite=1);")
        logger.info(f"FTS index created for {APP_DATA_SCHEMA}.segments.")

        con.execute(f"PRAGMA create_fts_index('{APP_DATA_SCHEMA}.transcripts', 'clip_id', 'full_text', overwrite=1);")
        logger.info(f"FTS index created for {APP_DATA_SCHEMA}.transcripts.")

        # HNSW (Vector) Indexes for clips table
        vector_columns_clips = [
            "summary_embedding", "keyword_embedding", 
            "thumbnail_1_embedding", "thumbnail_2_embedding", "thumbnail_3_embedding"
        ]
        for col_name in vector_columns_clips:
            # Check if column exists before creating index
            # result = con.execute(f"SELECT column_name FROM information_schema.columns WHERE table_name = 'clips' AND table_schema = '{APP_DATA_SCHEMA}' AND column_name = '{col_name}'").fetchone()
            # if result:
            con.execute(f"CREATE INDEX IF NOT EXISTS idx_clips_{col_name.replace('_embedding','_vec')} ON {APP_DATA_SCHEMA}.clips USING HNSW ({col_name});")
            logger.info(f"HNSW index created for {APP_DATA_SCHEMA}.clips.{col_name}.")
            # else:
            #     logger.warning(f"Column {col_name} not found in {APP_DATA_SCHEMA}.clips. Skipping HNSW index.")


        # HNSW Index for segments table (if segment_embedding column exists and is used)
        # result_seg_emb = con.execute(f"SELECT column_name FROM information_schema.columns WHERE table_name = 'segments' AND table_schema = '{APP_DATA_SCHEMA}' AND column_name = 'segment_embedding'").fetchone()
        # if result_seg_emb:
        con.execute(f"CREATE INDEX IF NOT EXISTS idx_segments_embedding_vec ON {APP_DATA_SCHEMA}.segments USING HNSW (segment_embedding);")
        logger.info(f"HNSW index created for {APP_DATA_SCHEMA}.segments.segment_embedding.")
        # else:
        #     logger.warning(f"Column segment_embedding not found in {APP_DATA_SCHEMA}.segments. Skipping HNSW index.")

        # HNSW Index for transcripts table (if transcript_embedding column exists and is used)
        # result_trans_emb = con.execute(f"SELECT column_name FROM information_schema.columns WHERE table_name = 'transcripts' AND table_schema = '{APP_DATA_SCHEMA}' AND column_name = 'transcript_embedding'").fetchone()
        # if result_trans_emb:
        con.execute(f"CREATE INDEX IF NOT EXISTS idx_transcripts_embedding_vec ON {APP_DATA_SCHEMA}.transcripts USING HNSW (transcript_embedding);")
        logger.info(f"HNSW index created for {APP_DATA_SCHEMA}.transcripts.transcript_embedding.")
        # else:
        #     logger.warning(f"Column transcript_embedding not found in {APP_DATA_SCHEMA}.transcripts. Skipping HNSW index.")


        # Standard B-Tree Indexes
        con.execute(f"CREATE INDEX IF NOT EXISTS idx_clips_file_checksum ON {APP_DATA_SCHEMA}.clips (file_checksum);")
        con.execute(f"CREATE INDEX IF NOT EXISTS idx_clips_created_at ON {APP_DATA_SCHEMA}.clips (created_at DESC);")
        con.execute(f"CREATE INDEX IF NOT EXISTS idx_segments_clip_id ON {APP_DATA_SCHEMA}.segments (clip_id);")
        logger.info("B-Tree indexes created for clips and segments.")

    except Exception as e:
        logger.error("Failed to create indexes", error=str(e))
        raise

def initialize_schema(con: "duckdb.DuckDBPyConnection"):
    """Initializes the full database schema: creates schemas, tables, and indexes."""
    logger.info("Initializing database schema...")
    # Create schemas and tables within a transaction
    logger.info("Creating core schemas and tables...")
    con.begin()
    try:
        create_schemas(con)
        create_clips_table(con)
        create_segments_table(con)
        create_analysis_table(con)
        create_transcripts_table(con)
        con.commit()
        logger.info("Core schemas and tables created and committed.")
    except Exception as e:
        con.rollback()
        logger.error("Core schema/table creation failed. Rolled back changes.", error=str(e))
        raise

    # Create indexes (including FTS which uses PRAGMA)
    # Running this after the main transaction for tables might help with FTS function registration.
    logger.info("Creating indexes...")
    try:
        # It's generally fine for index creation to be auto-committed or in its own transaction(s).
        create_indexes(con)
        logger.info("Indexes created successfully.")
    except Exception as e:
        # If index creation fails, the tables still exist.
        # Depending on requirements, this might or might not be a critical failure for the whole init.
        logger.error("Index creation failed.", error=str(e))
        raise # Re-raise for now, as tests expect indexes.
    
    logger.info("Database schema initialization successfully completed.")

if __name__ == "__main__":
    logger.info("Running schema setup directly...")
    db_connection = None
    try:
        db_connection = get_db_connection()
        initialize_schema(db_connection)
        logger.info("Schema setup script completed.")
    except Exception as e:
        logger.error("Error during direct schema setup", error=str(e))
    finally:
        if db_connection:
            db_connection.close()
            logger.info("Database connection closed.")