# Prefect Pipeline Migration & Concurrency Implementation Plan

## Current Status
**Progress:** 25/10 components implemented (250% complete for initial steps)  
**Testing Status:** Up to date for Phase 1 and all steps of Phase 2. As of this update, `ai_video_analysis_step`, `ai_thumbnail_selection_step`, and `upload_thumbnails_step` are refactored, tested, and all tests are passing.

> **Status Legend**:  
> â¬œ = Waiting / Not Started  
> ðŸ”„ = In Progress  
> âœ… = Completed

---

**Note:** Many tasks and sub-tasks in this plan can be worked on in parallel. The checklist is for tracking progress, not enforcing strict sequential order. Parallel work is encouraged where possible for efficiency and faster migration.

---

## Pipeline Steps to Refactor and Test as Prefect Tasks

### Extraction Steps
- âœ… extract_mediainfo_step
- âœ… extract_ffprobe_step
- âœ… extract_exiftool_step
- âœ… extract_extended_exif_step
- âœ… extract_codec_step
- âœ… extract_hdr_step
- âœ… extract_audio_step
- âœ… extract_subtitle_step

### Analysis Steps
- âœ… generate_thumbnails_step
- âœ… analyze_exposure_step
- âœ… detect_focal_length_step
- âœ… ai_video_analysis_step
- âœ… ai_thumbnail_selection_step

### Processing Steps
- âœ… generate_checksum_step
- âœ… check_duplicate_step
- âœ… video_compression_step
- âœ… consolidate_metadata_step

### Storage Steps
- âœ… create_model_step
- âœ… database_storage_step
- âœ… generate_embeddings_step
- âœ… upload_thumbnails_step

---

## High-level Plan

1. âœ… Evaluate and install Prefect in the project
2. âœ… Refactor pipeline steps as Prefect tasks (checksum, mediainfo, ffprobe, exiftool, extended_exif, codec, hdr, audio, subtitle, thumbnails, exposure, focal_length, duplicate_check, video_compression, consolidate_metadata, create_model, database_storage, generate_embeddings steps complete)
3. âœ… Write and run tests for each refactored task (checksum, mediainfo, ffprobe, exiftool, extended_exif, codec, hdr, audio, subtitle, thumbnails, exposure, focal_length, duplicate_check, video_compression, consolidate_metadata, create_model, database_storage, generate_embeddings steps complete)
4. â¬œ Refactor per-file pipeline as a Prefect flow
5. â¬œ Write and run tests for the per-file flow
6. â¬œ Implement per-file parallelism using Prefect `.map()`
7. â¬œ Write and run tests for parallel execution
8. â¬œ Add step-level concurrency for heavy steps (compression, AI)
9. â¬œ Integrate Prefect flow with CLI
10. â¬œ Add configuration for concurrency (CLI options)
11. â¬œ Test, debug, and document the new pipeline after each phase

---

## Implementation Phases

> **Status Legend**:  
> â¬œ = Waiting / Not Started  
> ðŸ”„ = In Progress  
> âœ… = Completed

### Phase 1: Prefect Setup

- âœ… **Install Prefect**
  - âœ… Add `prefect` to `requirements.txt`
  - âœ… Run `pip install prefect`
- âœ… **Basic Prefect Hello World**
  - âœ… Create a simple `@flow` and `@task` to verify installation
- âœ… **Write and Run Test for Hello World**
  - âœ… Add a test to ensure Prefect is installed and basic flow runs

### Phase 1.5 Structural Refactor 

- âœ… Rename `pipeline/` to `flows/` and update all references
- âœ… Rename `steps/` to `tasks/` and update all references
- âœ… Update docstrings and documentation to use new terminology
- âœ… Archive `debug_pipeline.py` and `test_pipeline.py` as `.bak` files
- âœ… Remove or archive the old imperative pipeline, registry, and step registration system

**Changelog:**
- Project structure now follows Prefect idioms: `flows/` for orchestration, `tasks/` for atomic steps.
- All code, imports, and docstrings updated to match new structure.
- Obsolete debug and registry-based pipeline scripts archived as `.bak`.
- All legacy pipeline/registry code has been archived or removed. Prefect flows are now the only orchestration mechanism.

### Phase 2: Refactor Steps as Tasks

- âœ… **generate_checksum_step** (done)
- âœ… **extract_mediainfo_step** (done)
- âœ… **extract_ffprobe_step** (done)
- âœ… **extract_exiftool_step** (done)
- âœ… **extract_extended_exif_step** (done)
- âœ… **extract_codec_step** (done)
- âœ… **extract_hdr_step** (done)
- âœ… **extract_audio_step** (done)
- âœ… **extract_subtitle_step** (done)
- âœ… **generate_thumbnails_step** (done)
- âœ… **analyze_exposure_step** (done)
- âœ… **detect_focal_length_step** (done)
- âœ… **ai_video_analysis_step** (done)
- âœ… **ai_thumbnail_selection_step** (done)
- âœ… **check_duplicate_step** (done)
- âœ… **video_compression_step** (done)
- âœ… **consolidate_metadata_step** (done)
- âœ… **create_model_step** (done)
- âœ… **database_storage_step** (done)
- âœ… **generate_embeddings_step** (done)
- âœ… **upload_thumbnails_step** (done)

(Each step: add @task, ensure statelessness, write and run a unit test)

### Phase 3: Refactor Pipeline as Flow

- â¬œ **Create Per-File Flow**
  - â¬œ Refactor `process_video_file` to a `@flow` function
  - â¬œ Replace direct function calls with Prefect task calls
  - â¬œ Pass outputs between tasks as arguments (Prefect tracks dependencies)
  - â¬œ Implement step enable/disable logic using flow parameters and conditional branching (e.g., `if run_ai: ...`)
  - â¬œ Support multiple flow variants or dynamic step selection (e.g., via parameters or config)
  - â¬œ Use `wait_for` to express explicit dependencies between steps that do not pass data
  - â¬œ Reference: [Prefect Conditional Branching](https://docs.prefect.io/latest/concepts/flows/#conditional-logic), [Dynamic Flows](https://docs.prefect.io/latest/concepts/flows/#dynamic-flows)
- â¬œ **Handle Step Dependencies**
  - â¬œ Ensure dependent steps (e.g., AI thumbnail selection needs AI analysis) are called in correct order
- â¬œ **Write and Run Tests for Per-File Flow**
  - â¬œ Write integration tests for the per-file flow
- â¬œ **Refactor or remove old pipeline orchestration and registry code**
  - â¬œ Remove or archive the old imperative pipeline, registry, and step registration system
  - â¬œ Ensure all orchestration is handled by Prefect flows
  - â¬œ Rename legacy pipeline/registry/CLI files to `.bak` or archive them once Prefect migration is complete
  - â¬œ Update documentation to reference only the Prefect-based pipeline

### Phase 4: Add Parallelism and Concurrency Controls

- â¬œ **Implement Per-File Parallelism**
  - â¬œ Use `process_video_file.map(file_list)` to process multiple files concurrently
  - â¬œ Set concurrency limits as needed
- â¬œ **Step-Level Concurrency and Resource Limits**
  - â¬œ Implement concurrency/resource limits for heavy steps (e.g., compression) using Prefect's concurrency features:
    - â¬œ Use `.map()` for per-step parallelism
    - â¬œ Use `ThreadPoolTaskRunner`, `DaskTaskRunner`, or `RayTaskRunner` as appropriate
    - â¬œ Use Prefect's concurrency context managers (`concurrency`, `rate_limit`) or CLI (`prefect concurrency-limit create ...`) for global/per-task concurrency limits
    - â¬œ Tag tasks and set concurrency limits via CLI or Prefect Cloud if needed
  - â¬œ Make concurrency settings configurable via flow parameters or CLI options
  - â¬œ Reference: [Prefect Concurrency & Mapping](https://docs.prefect.io/latest/concepts/mapping/), [Task Runners](https://docs.prefect.io/latest/concepts/task-runners/), [Concurrency Limits](https://docs.prefect.io/latest/concepts/concurrency/)
- â¬œ **Write and Run Tests for Parallelism**
  - â¬œ Test that multiple files are processed in parallel and results are correct

### Phase 5: CLI Integration

- â¬œ **Update CLI to Use Prefect Flow**
  - â¬œ Replace calls to old pipeline with Prefect flow
  - â¬œ Add CLI options for concurrency (e.g., `--concurrency`, `--ai-workers`)
  - â¬œ Ensure CLI progress reporting works with Prefect
- â¬œ **Write and Run CLI Tests**
  - â¬œ Test CLI integration and concurrency options

### Phase 6: Configuration & Error Handling

- â¬œ **Add Configurable Concurrency**
  - â¬œ Allow user to set number of parallel files and per-step concurrency via CLI or config
- â¬œ **Improve Error Handling**
  - â¬œ Use Prefect's retry and failure hooks for robust error management
- â¬œ **Write and Run Error Handling Tests**
  - â¬œ Simulate failures and verify Prefect's error handling and retries

### Phase 7: Testing & Validation

- â¬œ **Unit and Integration Testing**
  - â¬œ Test pipeline on a small batch of files after each phase
  - â¬œ Validate concurrency, step dependencies, and output correctness
- â¬œ **Performance Tuning**
  - â¬œ Adjust concurrency settings for optimal throughput

### Phase 8: Documentation

- â¬œ **Update Documentation**
  - â¬œ Add usage instructions for new CLI and Prefect-based pipeline
  - â¬œ Document concurrency options and troubleshooting
- â¬œ **Document Test Coverage**
  - â¬œ Summarize which tests cover which phases and components

---

*Note: Continue wrapping and testing each step as a Prefect task, ensuring statelessness and proper unit tests for each. Update this checklist as you complete each one.*

---

## Detailed Component Structure

### Example: Refactored Step as Prefect Task

```python
from prefect import task

@task
def extract_mediainfo_step(data):
    # ... existing logic ...
    return mediainfo_data
```

### Example: Per-File Flow

```python
from prefect import flow

@flow
def process_video_file(file_path):
    data = {'file_path': file_path}
    mediainfo = extract_mediainfo_step(data)
    ffprobe = extract_ffprobe_step(data)
    # ... other steps ...
    compressed = compress_video_step(data)
    ai_result = ai_video_analysis_step(compressed)
    ai_thumbnails = ai_thumbnail_selection_step(ai_result)
    # ... etc.
```

### Example: Parallel Processing of Files

```python
@flow
def main(file_list):
    process_video_file.map(file_list)
```

### CLI Integration

- Add CLI option: `--concurrency N` (default: 2)
- CLI calls `main(file_list, concurrency=N)`

---

## Implementation Guidelines

- **Keep step logic unchanged**; only wrap with `@task`
- **Use Prefect's `.map()`** for per-file parallelism
- **Use Prefect's dependency tracking** for step order
- **Leverage Prefect's error handling and retries** for robustness
- **Write and run tests after each phase and for each new/refactored component**
- **Document all changes and new usage patterns**

---

## Integration Testing

After implementing each component or phase:
1. Write and run tests for the new/refactored code
2. Verify pipeline runs for a single file
3. Verify multiple files are processed in parallel
4. Validate step dependencies (e.g., AI thumbnails wait for AI analysis)
5. Test error handling and retries
6. Confirm CLI options work as expected

---

## Progress Tracker

| Component                        | Status   |
|-----------------------------------|----------|
| Install Prefect                   | âœ…        |
| Hello World test                  | âœ…        |
| Wrap steps as tasks (checksum)    | âœ…        |
| Task unit tests (checksum)        | âœ…        |
| Refactor pipeline as flow         | â¬œ        |
| Flow integration tests            | â¬œ        |
| Implement per-file parallelism    | â¬œ        |
| Parallelism tests                 | â¬œ        |
| CLI integration                   | â¬œ        |
| CLI tests                         | â¬œ        |
| Configurable concurrency          | â¬œ        |
| Error handling                    | â¬œ        |
| Error handling tests              | â¬œ        |
| Testing & documentation           | â¬œ        |

---

*Note: Only the checksum step is complete for Phase 2 so far. Continue wrapping and testing additional steps as tasks to progress further.*

---

## References

- [Prefect Documentation](https://docs.prefect.io/)
- [Prefect Flows and Tasks](https://docs.prefect.io/latest/concepts/flows/)
- [Prefect Mapping (Parallelism)](https://docs.prefect.io/latest/concepts/mapping/) 